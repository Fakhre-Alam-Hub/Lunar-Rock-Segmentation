{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>Model Building and Tuning","metadata":{}},{"cell_type":"markdown","source":"### About the Dataset\n\nThis dataset contains 9766 realistic renders of lunar landscapes and their masks (segmented into three classes: sky, small rocks, bigger rocks). Additionally, a csv file of bounding boxes and cleaned masks of ground truths are provided.\n\nAn interesting feature of this dataset is that the images are synthetic; they were created using Planetside Software's Terragen. This isn't too obvious immediately as the renderings are highly realistic but it does make more sense after taking into account the scarcity of space imagery data.\n\nAcknowledgment: Romain Pessia and Genya Ishigami of the Space Robotics Group, Keio University, Japan. You can find the dataset https://www.kaggle.com/romainpessia/artificial-lunar-rocky-landscape-dataset\n\n### Libraries Used are:\n\n**Os:** The OS module in Python provides functions for interacting with the operating system.\n\n**OpenCV:** OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n\n**Glob:** glob (short for global) is used to return all file paths that match a specific pattern.\n\n**keras:** Keras is an open-source high-level Neural Network library, which is written in Python is capable enough to run on Theano, TensorFlow, or CNTK.\n\n**Numpy:**  It is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n\n**Tensorflow:** TensorFlow is a Python library for fast numerical computing created and released by Google. It is a foundation library that can be used to create Deep Learning models directly or by using wrapper libraries that simplify the process built on top of TensorFlow.\n\n**Matplotlib:** Matplotlib is a python library used to create 2D graphs and plots by using python scripts. It has a module named pyplot which makes things easy for plotting by providing feature to control line styles, font properties, formatting axes etc.\n\n**segmentation_models:** Python library with Neural Networks for Image Segmentation based on Keras and TensorFlow . The main features of this library are: High level API, 4 models architectures for binary and multi-class image segmentation (including legendary Unet) 25 available backbones for each architecture.\n\n**sklearn:** Scikit-learn (Sklearn) is the most useful and robust library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python.","metadata":{}},{"cell_type":"markdown","source":"## Modifying Mask\n\nRepresenting integer value to each class.","metadata":{}},{"cell_type":"code","source":"import cv2\nbase_path = '/content/drive/MyDrive/Lunar Rock Segmentation/data/images/clean'\n\nGROUND_MASK_DIR_PATH = '/content/drive/MyDrive/Lunar Rock Segmentation/data/images/cleanOriginal'\nground_mask_paths = [os.path.join(GROUND_MASK_DIR_PATH, x) for x in sorted(os.listdir(GROUND_MASK_DIR_PATH))]\n\nfor path in ground_mask_paths[:3]:\n    img_name = path.split('/')[-1]\n    mask = cv2.imread(path)\n    large_rock = mask[:,:,0]\n    small_rock = mask[:,:,1]\n    sky = mask[:,:,2]\n\n    output_mask = np.zeros(shape=mask.shape)\n\n    if large_rock.any():\n        output_mask[large_rock > 0] = 1\n        \n    if small_rock.any():\n        output_mask[small_rock > 0] = 2\n        \n    if sky.any():\n        output_mask[sky > 0] = 3\n        \n    output_mask = output_mask.astype(np.int32)\n    cv2.imwrite(os.path.join(base_path, img_name), output_mask)\n    \nprint(\"Image written to file-system \")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing libraries\n\nsegmentation_models is a python library with Neural Networks for Image Segmentation based on Keras and TensorFlow.\n\nThe main features of this library are:\n\n* High level API (just two lines of code to create model for segmentation)\n* 4 models architectures for binary and multi-class image segmentation (including legendary Unet)\n* 25 available backbones for each architecture\n* All backbones have pre-trained weights for faster and better convergence\n* Helpful segmentation losses (Jaccard, Dice, Focal) and metrics (IoU, F-score)","metadata":{}},{"cell_type":"code","source":"!pip install segmentation_models","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport segmentation_models as sm\nimport glob\nimport cv2\nimport os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport keras \nfrom sklearn.model_selection import train_test_split","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Provide environment variable SM_FRAMEWORK=keras / SM_FRAMEWORK=tf.keras before import segmentation_models\n* Change framework sm.set_framework('keras') / sm.set_framework('tf.keras')","metadata":{}},{"cell_type":"code","source":"os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\nsm.set_framework('tf.keras')\nkeras.backend.set_image_data_format('channels_last')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing Pipeline","metadata":{}},{"cell_type":"code","source":"H = 256\nW = 256\n\n'''This function is used to return the list of path for images and masks in\nsorted order from the given directory respectively.'''\n# function to return list of image paths and mask paths \ndef process_data(IMG_DIR, MASK_DIR):\n    images = [os.path.join(IMG_DIR, x) for x in sorted(os.listdir(IMG_DIR))]\n    masks = [os.path.join(MASK_DIR, x) for x in sorted(os.listdir(MASK_DIR))]\n\n    return images, masks\n\n'''This function is used to return splitted list of images and corresponding \nmask paths in train and test by providing test size.'''\n# function to load data and train test split\ndef load_data(IMG_DIR, MASK_DIR):\n    X, y = process_data(IMG_DIR, MASK_DIR)\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42)\n    \n    return X_train, X_test, y_train, y_test\n\n'''This function is used to read images. It takes image path as input. \nAfter reading image it is resized by width and height provide above(256 x 256). \nNext normalization is done by dividing each values with 255. And the result is returned.'''\n# function to read image\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    return x\n\n# function to read mask\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    # x = x - 1\n    x = x.astype(np.int32)\n    return x\n\n\n'''This function is used to generate tensorflow data pipeline. \nThe tensorflow data pipeline is mapped to function ‘preprocess’ .'''\n# function for tensorflow dataset pipeline\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.shuffle(buffer_size=5000)\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(2)\n    return dataset\n\n'''This function takes image and mask path. \nIt reads the image and mask as provided by paths. \nMask is one hot encoded for multi class segmentation (here 4 class).'''\n# function to read image and mask amd create one hot encoding for mask\ndef preprocess(x, y):\n    def f(x, y):\n        x = x.decode()\n        y = y.decode()\n\n        image = read_image(x)\n        mask = read_mask(y)\n\n        return image, mask\n\n    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n    mask = tf.one_hot(mask, 4, dtype=tf.int32)\n    image.set_shape([H, W, 3])\n    mask.set_shape([H, W, 4])\n\n    return image, mask","metadata":{"execution":{"iopub.status.busy":"2021-11-18T11:48:53.75267Z","iopub.execute_input":"2021-11-18T11:48:53.753024Z","iopub.status.idle":"2021-11-18T11:48:53.795011Z","shell.execute_reply.started":"2021-11-18T11:48:53.752913Z","shell.execute_reply":"2021-11-18T11:48:53.794237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"'''RENDER_IMAGE_DIR_PATH: ‘Path of image directory’\nGROUND_MASK_DIR_PATH: ‘Path of mask directory’\n\nHere load_data function is called. This will load the dataset paths and \nsplit it into X_train, X_test, y_train, y_test '''\n\nRENDER_IMAGE_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\nGROUND_MASK_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n\nX_train, X_test, y_train, y_test = load_data(RENDER_IMAGE_DIR_PATH, GROUND_MASK_DIR_PATH)\nprint(f\"Dataset:\\n Train: {len(X_train)} \\n Test: {len(X_test)}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate tensorflow data pipeline","metadata":{}},{"cell_type":"code","source":"batch_size = 8\n\n'''Here the tf_dataset function is called will generate the tensorflow data pipeline.'''\n# calling tf_dataset\ntrain_dataset = tf_dataset(X_train, y_train, batch=batch_size)\nvalid_dataset = tf_dataset(X_test, y_test, batch=batch_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating U-net Architecture\n\n**segmentation_models** is a library used for creating U-net model with vgg16 as a backbone and with weights of imagenet.","metadata":{}},{"cell_type":"code","source":"import segmentation_models as sm\n\nBACKBONE = 'vgg16'\ninput_shape = (256, 256, 3)\nn_classes = 4\nactivation = 'softmax'\n\n# using segmentation_models to create U-net with vgg16 as a backbone\n# and pretrained imagenet weights\nmodel = sm.Unet(backbone_name = BACKBONE, \n                input_shape = input_shape, \n                classes = n_classes, \n                activation = activation,\n                encoder_weights = 'imagenet')\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compile model","metadata":{}},{"cell_type":"code","source":"\"\"\" Hyperparameters \"\"\"\nlr = 1e-4\nbatch_size = 16\nepochs = 5\n\n# metrics for result validation\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n\n# compiling the model\nmodel.compile(loss = 'categorical_crossentropy', \n              optimizer = tf.keras.optimizers.Adam(lr), \n              metrics = metrics)\n\ntrain_steps = len(X_train)//batch_size\nvalid_steps = len(X_test)//batch_size\n\n\n\"\"\" Callbacks \"\"\"\ncurrent_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ncallbacks = [\n        ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n                        monitor='val_iou_score', verbose=0, \n                        mode='max', save_best_model=True),\n             \n        ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n                          factor=0.1, verbose=0, min_lr=1e-6),\n             \n        EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n\n        TensorBoard(f'models/logs_{current_datetime}')\n    ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nmodel is compiled with **loss**=\"categorical_crossentropy\",  **optimizer**=Adam, **metrics**=iou_score\n\n**Callbacks** is a tool to customize the behavior of a Keras model during training, evaluation, or inference.\n\n**ModelCheckpoint:** used  to periodically save your model during training.\n\n**ReduceLROnPlateau:** Reduce learning rate when a metric has stopped improving.\n\n**EarlyStopping:** Stop training when a monitored metric has stopped improving.\n\n**TensorBoard:** Enable visualizations for TensorBoard.","metadata":{}},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"# Fitting the model\nmodel_history = model.fit(train_dataset,\n        steps_per_epoch=train_steps,\n        validation_data=valid_dataset,\n        validation_steps=valid_steps,\n        epochs=epochs,\n        callbacks=callbacks\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict from model","metadata":{}},{"cell_type":"code","source":"# function to predict result \ndef predict_image(img_path, mask_path, model):\n    H = 256\n    W = 256\n    num_classes = 4\n\n    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n    img = cv2.resize(img, (W, H))\n    img = img / 255.0\n    img = img.astype(np.float32)\n\n    ## Read mask\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (W, H))   ## (256, 256)\n    mask = np.expand_dims(mask, axis=-1) ## (256, 256, 1)\n    mask = mask * (255/num_classes)\n    mask = mask.astype(np.int32)\n    mask = np.concatenate([mask, mask, mask], axis=2)\n\n    ## Prediction\n    pred_mask = model.predict(np.expand_dims(img, axis=0))[0]\n    pred_mask = np.argmax(pred_mask, axis=-1)\n    pred_mask = np.expand_dims(pred_mask, axis=-1)\n    pred_mask = pred_mask * (255/num_classes)\n    pred_mask = pred_mask.astype(np.int32)\n    pred_mask = np.concatenate([pred_mask, pred_mask, pred_mask], axis=2)\n\n    return img, mask, pred_mask","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to display result\ndef display(display_list):\n  plt.figure(figsize=(12, 10))\n\n  title = ['Input Image', 'True Mask', 'Predicted Mask', 'Mask On Image']\n\n  for i in range(len(display_list)):\n    plt.subplot(1, len(display_list), i+1)\n    plt.title(title[i])\n    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n    plt.axis('off')\n  plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = '../input/artificial-lunar-rocky-landscape-dataset/images/render/render0041.png'\nmask_path = '../input/artificial-lunar-rocky-landscape-dataset/images/clean/clean0041.png'\n\nimg, mask, pred_mask = predict_image(img_path, mask_path, model)\n\ndisplay([img, mask, pred_mask])","metadata":{},"execution_count":null,"outputs":[]}]}