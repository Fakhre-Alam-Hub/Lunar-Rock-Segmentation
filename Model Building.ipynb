{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"execution":{"iopub.execute_input":"2021-11-17T04:03:37.382068Z","iopub.status.busy":"2021-11-17T04:03:37.38134Z","iopub.status.idle":"2021-11-17T04:04:13.808183Z","shell.execute_reply":"2021-11-17T04:04:13.80743Z","shell.execute_reply.started":"2021-11-17T04:03:37.381976Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# <center>Model Building"]},{"cell_type":"markdown","metadata":{},"source":["### About the Dataset\n","\n","This dataset contains 9766 realistic renders of lunar landscapes and their masks (segmented into three classes: sky, small rocks, bigger rocks). Additionally, a csv file of bounding boxes and cleaned masks of ground truths are provided.\n","\n","An interesting feature of this dataset is that the images are synthetic; they were created using Planetside Software's Terragen. This isn't too obvious immediately as the renderings are highly realistic but it does make more sense after taking into account the scarcity of space imagery data.\n","\n","Acknowledgment: Romain Pessia and Genya Ishigami of the Space Robotics Group, Keio University, Japan. You can find the dataset https://www.kaggle.com/romainpessia/artificial-lunar-rocky-landscape-dataset\n","\n","### Libraries Used are:\n","\n","**Os:** The OS module in Python provides functions for interacting with the operating system.\n","\n","**OpenCV:** OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n","\n","**Glob:** glob (short for global) is used to return all file paths that match a specific pattern.\n","\n","**keras:** Keras is an open-source high-level Neural Network library, which is written in Python is capable enough to run on Theano, TensorFlow, or CNTK.\n","\n","**Numpy:**  It is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n","\n","**Tensorflow:** TensorFlow is a Python library for fast numerical computing created and released by Google. It is a foundation library that can be used to create Deep Learning models directly or by using wrapper libraries that simplify the process built on top of TensorFlow.\n","\n","**Matplotlib:** Matplotlib is a python library used to create 2D graphs and plots by using python scripts. It has a module named pyplot which makes things easy for plotting by providing feature to control line styles, font properties, formatting axes etc.\n","\n","**segmentation_models:** Python library with Neural Networks for Image Segmentation based on Keras and TensorFlow . The main features of this library are: High level API, 4 models architectures for binary and multi-class image segmentation (including legendary Unet) 25 available backbones for each architecture.\n","\n","**sklearn:** Scikit-learn (Sklearn) is the most useful and robust library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python."]},{"cell_type":"markdown","metadata":{},"source":["# Importing libraries\n","\n","segmentation_models is a python library with Neural Networks for Image Segmentation based on Keras and TensorFlow.\n","\n","The main features of this library are:\n","\n","* High level API (just two lines of code to create model for segmentation)\n","* 4 models architectures for binary and multi-class image segmentation (including legendary Unet)\n","* 25 available backbones for each architecture\n","* All backbones have pre-trained weights for faster and better convergence\n","* Helpful segmentation losses (Jaccard, Dice, Focal) and metrics (IoU, F-score)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-17T04:09:41.903774Z","iopub.status.busy":"2021-11-17T04:09:41.903501Z","iopub.status.idle":"2021-11-17T04:09:52.005597Z","shell.execute_reply":"2021-11-17T04:09:52.004701Z","shell.execute_reply.started":"2021-11-17T04:09:41.903744Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!pip install segmentation_models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-17T04:09:56.902978Z","iopub.status.busy":"2021-11-17T04:09:56.902709Z","iopub.status.idle":"2021-11-17T04:09:57.203832Z","shell.execute_reply":"2021-11-17T04:09:57.203049Z","shell.execute_reply.started":"2021-11-17T04:09:56.902946Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import segmentation_models as sm\n","import glob\n","import cv2\n","import os\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import keras \n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{},"source":["* Provide environment variable SM_FRAMEWORK=keras / SM_FRAMEWORK=tf.keras before import segmentation_models\n","* Change framework sm.set_framework('keras') / sm.set_framework('tf.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-15T13:11:21.141118Z","iopub.status.busy":"2021-11-15T13:11:21.140723Z","iopub.status.idle":"2021-11-15T13:11:21.581518Z","shell.execute_reply":"2021-11-15T13:11:21.580797Z","shell.execute_reply.started":"2021-11-15T13:11:21.141071Z"},"trusted":true},"outputs":[],"source":["os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n","sm.set_framework('tf.keras')\n","keras.backend.set_image_data_format('channels_last')"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preprocessing Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-17T04:04:19.239711Z","iopub.status.busy":"2021-11-17T04:04:19.239432Z","iopub.status.idle":"2021-11-17T04:04:19.254816Z","shell.execute_reply":"2021-11-17T04:04:19.253995Z","shell.execute_reply.started":"2021-11-17T04:04:19.239673Z"},"trusted":true},"outputs":[],"source":["H = 256 # height of image\n","W = 256 # width of image\n","\n","'''This function is used to return the list of path for images and masks in\n","sorted order from the given directory respectively.'''\n","# function to return list of image paths and mask paths \n","def process_data(IMG_DIR, MASK_DIR):\n","    images = [os.path.join(IMG_DIR, x) for x in sorted(os.listdir(IMG_DIR))]\n","    masks = [os.path.join(MASK_DIR, x) for x in sorted(os.listdir(MASK_DIR))]\n","\n","    return images, masks\n","\n","'''This function is used to return splitted list of images and corresponding \n","mask paths in train and test by providing test size.'''\n","# function to load data and train test split\n","def load_data(IMG_DIR, MASK_DIR):\n","    X, y = process_data(IMG_DIR, MASK_DIR)\n","    \n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=42)\n","    \n","    return X_train, X_test, y_train, y_test\n","\n","'''This function is used to read images. It takes image path as input. \n","After reading image it is resized by width and height provide above(256 x 256). \n","Next normalization is done by dividing each values with 255. And the result is returned.'''\n","# function to read image\n","def read_image(x):\n","    x = cv2.imread(x, cv2.IMREAD_COLOR)\n","    x = cv2.resize(x, (W, H))\n","    x = x / 255.0\n","    x = x.astype(np.float32)\n","    return x\n","\n","'''This function is used to read masks.'''\n","# function to read mask\n","def read_mask(x):\n","    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n","    x = cv2.resize(x, (W, H))\n","    x = x.astype(np.int32)\n","    return x\n","\n","'''This function is used to generate tensorflow data pipeline. \n","The tensorflow data pipeline is mapped to function ‘preprocess’ .'''\n","# function for tensorflow dataset pipeline\n","def tf_dataset(x, y, batch=8):\n","    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","    dataset = dataset.shuffle(buffer_size=5000)\n","    dataset = dataset.map(preprocess)\n","    dataset = dataset.batch(batch)\n","    dataset = dataset.repeat()\n","    dataset = dataset.prefetch(2)\n","    return dataset\n","\n","'''This function takes image and mask path. \n","It reads the image and mask as provided by paths. \n","Mask is one hot encoded for multi class segmentation (here 4 class).'''\n","# function to read image and mask amd create one hot encoding for mask\n","def preprocess(x, y):\n","    def f(x, y):\n","        x = x.decode()\n","        y = y.decode()\n","\n","        image = read_image(x)\n","        mask = read_mask(y)\n","\n","        return image, mask\n","\n","    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n","    mask = tf.one_hot(mask, 4, dtype=tf.int32)\n","    image.set_shape([H, W, 3])\n","    mask.set_shape([H, W, 4])\n","\n","    return image, mask"]},{"cell_type":"markdown","metadata":{},"source":["## Load the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-17T04:06:45.291036Z","iopub.status.busy":"2021-11-17T04:06:45.290787Z","iopub.status.idle":"2021-11-17T04:06:45.352319Z","shell.execute_reply":"2021-11-17T04:06:45.351536Z","shell.execute_reply.started":"2021-11-17T04:06:45.291007Z"},"trusted":true},"outputs":[],"source":["'''RENDER_IMAGE_DIR_PATH: ‘Path of image directory’\n","GROUND_MASK_DIR_PATH: ‘Path of mask directory’\n","\n","Here load_data function is called. This will load the dataset paths and \n","split it into X_train, X_test, y_train, y_test '''\n","\n","RENDER_IMAGE_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\n","GROUND_MASK_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n","\n","X_train, X_test, y_train, y_test = load_data(RENDER_IMAGE_DIR_PATH, GROUND_MASK_DIR_PATH)\n","print(f\"Dataset:\\n Train: {len(X_train)} \\n Test: {len(X_test)}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Generate tensorflow data pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-17T04:08:25.384113Z","iopub.status.busy":"2021-11-17T04:08:25.383825Z","iopub.status.idle":"2021-11-17T04:08:27.897319Z","shell.execute_reply":"2021-11-17T04:08:27.896598Z","shell.execute_reply.started":"2021-11-17T04:08:25.38408Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["batch_size = 8\n","\n","'''Here the tf_dataset function is called will generate the tensorflow data pipeline.'''\n","# calling tf_dataset\n","train_dataset = tf_dataset(X_train, y_train, batch=batch_size)\n","valid_dataset = tf_dataset(X_test, y_test, batch=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["## Creating U-net Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-17T04:09:02.014142Z","iopub.status.busy":"2021-11-17T04:09:02.013426Z","iopub.status.idle":"2021-11-17T04:09:02.302913Z","shell.execute_reply":"2021-11-17T04:09:02.302161Z","shell.execute_reply.started":"2021-11-17T04:09:02.014099Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\n","from tensorflow.keras.models import Model\n","\n","'''conv_block it is used to create one block with two convolution layer \n","followed by BatchNormalization and activation function relu. \n","If the pooling is required then Maxpool2D is applied and return it else not.'''\n","# function to create convolution block\n","def conv_block(inputs, filters, pool=True):\n","    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    if pool == True:\n","        p = MaxPool2D((2, 2))(x)\n","        return x, p\n","    else:\n","        return x\n","\n","'''build_unet it is used to create the U-net architecture.'''\n","# function to build U-net\n","def build_unet(shape, num_classes):\n","    inputs = Input(shape)\n","\n","    \"\"\" Encoder \"\"\"\n","    x1, p1 = conv_block(inputs, 16, pool=True)\n","    x2, p2 = conv_block(p1, 32, pool=True)\n","    x3, p3 = conv_block(p2, 48, pool=True)\n","    x4, p4 = conv_block(p3, 64, pool=True)\n","\n","    \"\"\" Bridge \"\"\"\n","    b1 = conv_block(p4, 128, pool=False)\n","\n","    \"\"\" Decoder \"\"\"\n","    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n","    c1 = Concatenate()([u1, x4])\n","    x5 = conv_block(c1, 64, pool=False)\n","\n","    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n","    c2 = Concatenate()([u2, x3])\n","    x6 = conv_block(c2, 48, pool=False)\n","\n","    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n","    c3 = Concatenate()([u3, x2])\n","    x7 = conv_block(c3, 32, pool=False)\n","\n","    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n","    c4 = Concatenate()([u4, x1])\n","    x8 = conv_block(c4, 16, pool=False)\n","\n","    \"\"\" Output layer \"\"\"\n","    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n","\n","    return Model(inputs, output)"]},{"cell_type":"markdown","metadata":{},"source":["**For Contracting Path:** the **conv_block** function is called four time which will create four block with pooling (pool = True). The process is repeated 3 more times.\n","\n","**For Bridge:** the **conv_block** function is called one time without pooling (pool=False).\n","\n","**For Expansive Path: UpSampling2D** is used to expands the size of images. This expanded  image is concatenated with the corresponding image from the contracting path, The reason here is to combine the information from the previous layers in order to get a more precise prediction. And now **conv_block** function is called without pooling (pool=False). The process is repeated 3 more times.\n","\n","The last step is to reshape the image to satisfy our prediction requirements. The last layer is a convolution layer with 1 filter of size 1x1."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-17T04:09:03.382981Z","iopub.status.busy":"2021-11-17T04:09:03.382542Z","iopub.status.idle":"2021-11-17T04:09:03.863271Z","shell.execute_reply":"2021-11-17T04:09:03.862468Z","shell.execute_reply.started":"2021-11-17T04:09:03.382942Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# calling build_unet function\n","model = build_unet((256, 256, 3), 4)\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Load model and compile"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-17T04:10:23.615687Z","iopub.status.busy":"2021-11-17T04:10:23.614863Z","iopub.status.idle":"2021-11-17T04:10:24.326267Z","shell.execute_reply":"2021-11-17T04:10:24.325114Z","shell.execute_reply.started":"2021-11-17T04:10:23.61563Z"},"trusted":true},"outputs":[],"source":["# importing libraries\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n","from segmentation_models.metrics import iou_score\n","import datetime, os\n","\n","\"\"\" Hyperparameters \"\"\"\n","shape = (256, 256, 3)\n","num_classes = 4\n","lr = 1e-4\n","batch_size = 16\n","epochs = 5\n","\n","\"\"\" Model \"\"\"\n","model = build_unet(img_shape, num_classes)\n","model.compile(loss=\"categorical_crossentropy\", \n","              optimizer=tf.keras.optimizers.Adam(lr), \n","              metrics=[iou_score])\n","\n","\n","train_steps = len(X_train)//batch_size\n","valid_steps = len(X_test)//batch_size\n","\n","\n","\"\"\" Callbacks \"\"\"\n","current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","\n","callbacks = [\n","        ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n","                        monitor='val_iou_score', verbose=0, \n","                        mode='max', save_best_model=True),\n","             \n","        ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n","                          factor=0.1, verbose=0, min_lr=1e-6),\n","             \n","        EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n","\n","        TensorBoard(f'models/logs_{current_datetime}')\n","    ]"]},{"cell_type":"markdown","metadata":{},"source":["**build_unet** is called to create U-net model, it takes image shape and number of class as input.\n","\n","Next model is compiled with **loss**=\"categorical_crossentropy\",  **optimizer**=Adam, **metrics**=iou_score\n","\n","**Callbacks** is a tool to customize the behavior of a Keras model during training, evaluation, or inference.\n","\n","**ModelCheckpoint:** used  to periodically save your model during training.\n","\n","**ReduceLROnPlateau:** Reduce learning rate when a metric has stopped improving.\n","\n","**EarlyStopping:** Stop training when a monitored metric has stopped improving.\n","\n","**TensorBoard:** Enable visualizations for TensorBoard."]},{"cell_type":"markdown","metadata":{},"source":["## Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-17T04:10:29.63317Z","iopub.status.busy":"2021-11-17T04:10:29.632631Z","iopub.status.idle":"2021-11-17T04:10:48.922438Z","shell.execute_reply":"2021-11-17T04:10:48.920034Z","shell.execute_reply.started":"2021-11-17T04:10:29.633132Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["'''model.fit is used to train the model'''\n","model_history = model.fit(train_dataset,\n","        steps_per_epoch=train_steps,\n","        validation_data=valid_dataset,\n","        validation_steps=valid_steps,\n","        epochs=epochs,\n","        callbacks=callbacks\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["## Predict from model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-15T13:27:58.79118Z","iopub.status.busy":"2021-11-15T13:27:58.790822Z","iopub.status.idle":"2021-11-15T13:27:58.802558Z","shell.execute_reply":"2021-11-15T13:27:58.801812Z","shell.execute_reply.started":"2021-11-15T13:27:58.791142Z"},"trusted":true},"outputs":[],"source":["# function to predict result \n","def predict_image(img_path, mask_path, model):\n","    H = 256\n","    W = 256\n","    num_classes = 4\n","\n","    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n","    img = cv2.resize(img, (W, H))\n","    img = img / 255.0\n","    img = img.astype(np.float32)\n","\n","    ## Read mask\n","    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","    mask = cv2.resize(mask, (W, H))   ## (256, 256)\n","    mask = np.expand_dims(mask, axis=-1) ## (256, 256, 1)\n","    mask = mask * (255/num_classes)\n","    mask = mask.astype(np.int32)\n","    mask = np.concatenate([mask, mask, mask], axis=2)\n","\n","    ## Prediction\n","    pred_mask = model.predict(np.expand_dims(img, axis=0))[0]\n","    pred_mask = np.argmax(pred_mask, axis=-1)\n","    pred_mask = np.expand_dims(pred_mask, axis=-1)\n","    pred_mask = pred_mask * (255/num_classes)\n","    pred_mask = pred_mask.astype(np.int32)\n","    pred_mask = np.concatenate([pred_mask, pred_mask, pred_mask], axis=2)\n","\n","    return img, mask, pred_mask"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# function to display result\n","def display(display_list):\n","  plt.figure(figsize=(12, 10))\n","\n","  title = ['Input Image', 'True Mask', 'Predicted Mask', 'Mask On Image']\n","\n","  for i in range(len(display_list)):\n","    plt.subplot(1, len(display_list), i+1)\n","    plt.title(title[i])\n","    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n","    plt.axis('off')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-15T13:52:06.099044Z","iopub.status.busy":"2021-11-15T13:52:06.098774Z","iopub.status.idle":"2021-11-15T13:52:06.610808Z","shell.execute_reply":"2021-11-15T13:52:06.610137Z","shell.execute_reply.started":"2021-11-15T13:52:06.099016Z"},"trusted":true},"outputs":[],"source":["img_path = '../input/artificial-lunar-rocky-landscape-dataset/images/render/render0041.png'\n","mask_path = '../input/artificial-lunar-rocky-landscape-dataset/images/clean/clean0041.png'\n","\n","img, mask, pred_mask = predict_image(img_path, mask_path, model)\n","\n","display([img, mask, pred_mask])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
